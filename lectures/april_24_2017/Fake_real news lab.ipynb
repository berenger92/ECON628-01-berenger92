{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://images.efollett.com/htmlroot/images/templates/storeLogos/CA/864.gif\" style=\"float: right;\"> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ECON628-01 \n",
    "### Fake real News\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjors_000\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read yelp.csv into a DataFrame\n",
    "url = 'C:/Users/mjors_000/Desktop/ECON628-01-berenger92/datasets/fake_real_news/fake_or_real_news.csv/fake_or_real_news.csv'\n",
    "fake = pd.read_csv(url, encoding='unicode-escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillaryâs Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>â Kaydee King (@KaydeeKing) November 9, 2016...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                     You Can Smell Hillaryâs Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  â Kaydee King (@KaydeeKing) November 9, 2016...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame called news_real_fake that only contains the fake or real news\n",
    "news_real_fake = fake[(fake.label=='FAKE') | (fake.label=='REAL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL    0.500552\n",
      "FAKE    0.499448\n",
      "Name: label, dtype: float64\n",
      "\n",
      "(6335L,) (6335L,)\n"
     ]
    }
   ],
   "source": [
    "# define X and y\n",
    "X = news_real_fake.text\n",
    "y = news_real_fake.label\n",
    "print y.value_counts(normalize=True)\n",
    "print ''\n",
    "print X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4751L,) (4751L,)\n",
      "\n",
      "(1584L,) (1584L,)\n"
     ]
    }
   ],
   "source": [
    "# split the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print X_train.shape, y_train.shape\n",
    "print ''\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Daniel Greenfield, a Shillman Journalism Fellow at the Freedom Center, is a New York writer focusing on radical Islam. \\nIn the final stretch of the election, Hillary Rodham Clinton has gone to war with the FBI. \\nThe word \\xe2\\x80\\x9cunprecedented\\xe2\\x80\\x9d has been thrown around so often this election that it ought to be retired. But it\\xe2\\x80\\x99s still unprecedented for the nominee of a major political party to go war with the FBI. \\nBut that\\xe2\\x80\\x99s exactly what Hillary and her people have done. Coma patients just waking up now and watching an hour of CNN from their hospital beds would assume that FBI Director James Comey is Hillary\\xe2\\x80\\x99s opponent in this election. \\nThe FBI is under attack by everyone from Obama to CNN. Hillary\\xe2\\x80\\x99s people have circulated a letter attacking Comey. There are currently more media hit pieces lambasting him than targeting Trump. It wouldn\\xe2\\x80\\x99t be too surprising if the Clintons or their allies were to start running attack ads against the FBI. \\nThe FBI\\xe2\\x80\\x99s leadership is being warned that the entire left-wing establishment will form a lynch mob if they continue going after Hillary. And the FBI\\xe2\\x80\\x99s credibility is being attacked by the media and the Democrats to preemptively head off the results of the investigation of the Clinton Foundation and Hillary Clinton. \\nThe covert struggle between FBI agents and Obama\\xe2\\x80\\x99s DOJ people has gone explosively public. \\nThe New York Times has compared Comey to J. Edgar Hoover. Its bizarre headline, \\xe2\\x80\\x9cJames Comey Role Recalls Hoover\\xe2\\x80\\x99s FBI, Fairly or Not\\xe2\\x80\\x9d practically admits up front that it\\xe2\\x80\\x99s spouting nonsense. The Boston Globe has published a column calling for Comey\\xe2\\x80\\x99s resignation. Not to be outdone, Time has an editorial claiming that the scandal is really an attack on all women. \\nJames Carville appeared on MSNBC to remind everyone that he was still alive and insane. He accused Comey of coordinating with House Republicans and the KGB. And you thought the \\xe2\\x80\\x9cvast right wing conspiracy\\xe2\\x80\\x9d was a stretch. \\nCountless media stories charge Comey with violating procedure. Do you know what\\xe2\\x80\\x99s a procedural violation? Emailing classified information stored on your bathroom server. \\nSenator Harry Reid has sent Comey a letter accusing him of violating the Hatch Act. The Hatch Act is a nice idea that has as much relevance in the age of Obama as the Tenth Amendment. But the cable news spectrum quickly filled with media hacks glancing at the Wikipedia article on the Hatch Act under the table while accusing the FBI director of one of the most awkward conspiracies against Hillary ever. \\nIf James Comey is really out to hurt Hillary, he picked one hell of a strange way to do it. \\nNot too long ago Democrats were breathing a sigh of relief when he gave Hillary Clinton a pass in a prominent public statement. If he really were out to elect Trump by keeping the email scandal going, why did he trash the investigation? Was he on the payroll of House Republicans and the KGB back then and playing it coy or was it a sudden development where Vladimir Putin and Paul Ryan talked him into taking a look at Anthony Weiner\\xe2\\x80\\x99s computer? \\nEither Comey is the most cunning FBI director that ever lived or he\\xe2\\x80\\x99s just awkwardly trying to navigate a political mess that has trapped him between a DOJ leadership whose political futures are tied to Hillary\\xe2\\x80\\x99s victory and his own bureau whose apolitical agents just want to be allowed to do their jobs. \\nThe only truly mysterious thing is why Hillary and her associates decided to go to war with a respected Federal agency. Most Americans like the FBI while Hillary Clinton enjoys a 60% unfavorable rating. \\nAnd it\\xe2\\x80\\x99s an interesting question. \\nHillary\\xe2\\x80\\x99s old strategy was to lie and deny that the FBI even had a criminal investigation underway. Instead her associates insisted that it was a security review. The FBI corrected her and she shrugged it off. But the old breezy denial approach has given way to a savage assault on the FBI. \\nPretending that nothing was wrong was a bad strategy, but it was a better one that picking a fight with the FBI while lunatic Clinton associates try to claim that the FBI is really the KGB. \\nThere are two possible explanations. \\nHillary Clinton might be arrogant enough to lash out at the FBI now that she believes that victory is near. The same kind of hubris that led her to plan her victory fireworks display could lead her to declare a war on the FBI for irritating her during the final miles of her campaign. \\nBut the other explanation is that her people panicked. \\nGoing to war with the FBI is not the behavior of a smart and focused presidential campaign. It\\xe2\\x80\\x99s an act of desperation. When a presidential candidate decides that her only option is to try and destroy the credibility of the FBI, that\\xe2\\x80\\x99s not hubris, it\\xe2\\x80\\x99s fear of what the FBI might be about to reveal about her. \\nDuring the original FBI investigation, Hillary Clinton was confident that she could ride it out. And she had good reason for believing that. But that Hillary Clinton is gone. In her place is a paranoid wreck. Within a short space of time the \\xe2\\x80\\x9cpositive\\xe2\\x80\\x9d Clinton campaign promising to unite the country has been replaced by a desperate and flailing operation that has focused all its energy on fighting the FBI. \\nThere\\xe2\\x80\\x99s only one reason for such bizarre behavior. \\nThe Clinton campaign has decided that an FBI investigation of the latest batch of emails poses a threat to its survival. And so it\\xe2\\x80\\x99s gone all in on fighting the FBI. It\\xe2\\x80\\x99s an unprecedented step born of fear. It\\xe2\\x80\\x99s hard to know whether that fear is justified. But the existence of that fear already tells us a whole lot. \\nClinton loyalists rigged the old investigation. They knew the outcome ahead of time as well as they knew the debate questions. Now suddenly they are no longer in control. And they are afraid. \\nYou can smell the fear. \\nThe FBI has wiretaps from the investigation of the Clinton Foundation. It\\xe2\\x80\\x99s finding new emails all the time. And Clintonworld panicked. The spinmeisters of Clintonworld have claimed that the email scandal is just so much smoke without fire. All that\\xe2\\x80\\x99s here is the appearance of impropriety without any of the substance. But this isn\\xe2\\x80\\x99t how you react to smoke. It\\xe2\\x80\\x99s how you respond to a fire. \\nThe misguided assault on the FBI tells us that Hillary Clinton and her allies are afraid of a revelation bigger than the fundamental illegality of her email setup. The email setup was a preemptive cover up. The Clinton campaign has panicked badly out of the belief, right or wrong, that whatever crime the illegal setup was meant to cover up is at risk of being exposed. \\nThe Clintons have weathered countless scandals over the years. Whatever they are protecting this time around is bigger than the usual corruption, bribery, sexual assaults and abuses of power that have followed them around throughout the years. This is bigger and more damaging than any of the allegations that have already come out. And they don\\xe2\\x80\\x99t want FBI investigators anywhere near it. \\nThe campaign against Comey is pure intimidation. It\\xe2\\x80\\x99s also a warning. Any senior FBI people who value their careers are being warned to stay away. The Democrats are closing ranks around their nominee against the FBI. It\\xe2\\x80\\x99s an ugly and unprecedented scene. It may also be their last stand. \\nHillary Clinton has awkwardly wound her way through numerous scandals in just this election cycle. But she\\xe2\\x80\\x99s never shown fear or desperation before. Now that has changed. Whatever she is afraid of, it lies buried in her emails with Huma Abedin. And it can bring her down like nothing else has.  '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What:** Separate text into units such as sentences or words\n",
    "- **Why:** Gives structure to previously unstructured text\n",
    "- **Notes:** Relatively easy with English language text, not easy with some languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
    "\n",
    "We will use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert text into a matrix of token counts\":s.\n",
    "\n",
    "\n",
    "### Count Vectorizer: a model like tree or lasso, that counts frequency of tokens/word. Then we fit it on the train, and print features/most common words or expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# use CountVectorizer to create document-term matrices from X_train and X_test\n",
    "##############################################################################\n",
    "\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4751, 67180)\n",
      "(1584, 67180)\n"
     ]
    }
   ],
   "source": [
    "# rows are documents, columns are terms (phrases) (aka \"tokens\" or \"features\")\n",
    "print X_train_dtm.shape\n",
    "print X_test_dtm.shape\n",
    "# Why do they have the same number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'00', u'000', u'0000', u'000000031', u'00000031', u'000035', u'00006', u'0001', u'0001pt', u'000billion', u'000ft', u'000km', u'000x', u'000\\xe2', u'001', u'0011', u'003', u'005', u'005s', u'006', u'006s', u'007s', u'007\\xe2', u'008s', u'009', u'00am', u'00p', u'00pm', u'01', u'010', u'012', u'013', u'015', u'018', u'01am', u'02', u'020', u'022', u'024', u'025', u'027', u'028', u'03', u'030', u'031', u'0325', u'033', u'034', u'035', u'039']\n"
     ]
    }
   ],
   "source": [
    "# first 50 features\n",
    "print vect.get_feature_names()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'zova', u'zucchini', u'zuccotti', u'zuck', u'zucker', u'zuckerberg', u'zuckerburg', u'zucman', u'zuesse', u'zukowski', u'zulema', u'zulia', u'zulu', u'zulus', u'zulus\\xe2', u'zulu\\xe2', u'zuma', u'zuniga', u'zurich', u'zurita', u'zuroff', u'zuylen', u'zvai', u'zvezda', u'zvi', u'zvulun', u'zwanzig', u'zweiter', u'zwick', u'zwischenmenschlicher', u'zxycmwjdxj', u'zyuganov', u'z\\xe2', u'\\xb91000', u'\\xb9500', u'\\xba\\xf0', u'\\xe2\\xbc', u'\\xe2\\xbd', u'\\xe3\\xaatre', u'\\xe3\\xaatre\\xe2', u'\\xe5\\xb950', u'\\xee\\xb2', u'\\xee\\xb5\\xee', u'\\xee\\xbd\\xee\\xb9\\xee\\xba\\xee', u'\\xf0\\xb2\\xf0\\xbd\\xf0', u'\\xf0\\xb3', u'\\xf0\\xb9', u'\\xf0\\xba\\xf0', u'\\xf0\\xbe\\xf0\\xba\\xf1', u'\\xf8\\xb9\\xf8']\n"
     ]
    }
   ],
   "source": [
    "# last 50 features\n",
    "print vect.get_feature_names()[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show vectorizer options\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CountVectorizer documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **lowercase:** boolean, True by default\n",
    "- Convert all characters to lowercase before tokenizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4751, 82963)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a count vectorizer that doesn't lowercase the words\n",
    "vect = CountVectorizer(lowercase=False)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm.shape # has more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'00', u'000', u'0000', u'000000031', u'00000031', u'000035', u'00006', u'0001', u'0001pt', u'000billion', u'000ft', u'000km', u'000x', u'000\\xc2', u'000\\xe2', u'001', u'0011', u'003', u'005', u'005s', u'006', u'006s', u'007s', u'007\\xe2', u'008s', u'009', u'00PM', u'00am', u'00p', u'01', u'010', u'012', u'013', u'015', u'018', u'01am', u'02', u'020', u'022', u'024', u'025', u'027', u'028', u'03', u'030', u'031', u'0325', u'033', u'034', u'035']\n"
     ]
    }
   ],
   "source": [
    "# first 50 features\n",
    "print vect.get_feature_names()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram_range\n",
    "---\n",
    "- **ngram_range:** tuple (min_n, max_n)\n",
    "- The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4751, 6780417)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1,4 ))\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\xee\\xb5\\xee \\xee\\xbd\\xee\\xb9\\xee\\xba\\xee', u'\\xee\\xb5\\xee \\xee\\xbd\\xee\\xb9\\xee\\xba\\xee t\\xe3\\xbcrk\\xe3', u'\\xee\\xb5\\xee \\xee\\xbd\\xee\\xb9\\xee\\xba\\xee t\\xe3\\xbcrk\\xe3 \\xf8\\xb9\\xf8', u'\\xee\\xbd\\xee\\xb9\\xee\\xba\\xee', u'\\xee\\xbd\\xee\\xb9\\xee\\xba\\xee t\\xe3\\xbcrk\\xe3', u'\\xee\\xbd\\xee\\xb9\\xee\\xba\\xee t\\xe3\\xbcrk\\xe3 \\xf8\\xb9\\xf8', u'\\xee\\xbd\\xee\\xb9\\xee\\xba\\xee t\\xe3\\xbcrk\\xe3 \\xf8\\xb9\\xf8 during', u'\\xf0\\xb2\\xf0\\xbd\\xf0', u'\\xf0\\xb2\\xf0\\xbd\\xf0 news', u'\\xf0\\xb2\\xf0\\xbd\\xf0 news google', u'\\xf0\\xb2\\xf0\\xbd\\xf0 news google appoints', u'\\xf0\\xb3', u'\\xf0\\xb3 among', u'\\xf0\\xb3 among the', u'\\xf0\\xb3 among the anti', u'\\xf0\\xb3 germany', u'\\xf0\\xb3 germany for', u'\\xf0\\xb3 germany for example', u'\\xf0\\xb3 in', u'\\xf0\\xb3 in other', u'\\xf0\\xb3 in other words', u'\\xf0\\xb3 the', u'\\xf0\\xb3 the unhrc', u'\\xf0\\xb3 the unhrc debacle', u'\\xf0\\xb3 these', u'\\xf0\\xb3 these states', u'\\xf0\\xb3 these states have', u'\\xf0\\xb9', u'\\xf0\\xb9 deutsch', u'\\xf0\\xb9 deutsch portugu\\xe3\\xaas', u'\\xf0\\xb9 deutsch portugu\\xe3\\xaas \\xee\\xb5\\xee', u'\\xf0\\xba\\xf0', u'\\xf0\\xba\\xf0 \\xf0\\xb9', u'\\xf0\\xba\\xf0 \\xf0\\xb9 deutsch', u'\\xf0\\xba\\xf0 \\xf0\\xb9 deutsch portugu\\xe3\\xaas', u'\\xf0\\xbe\\xf0\\xba\\xf1', u'\\xf0\\xbe\\xf0\\xba\\xf1 2016', u'\\xf0\\xbe\\xf0\\xba\\xf1 2016 \\xf0\\xb3', u'\\xf0\\xbe\\xf0\\xba\\xf1 2016 \\xf0\\xb3 among', u'\\xf0\\xbe\\xf0\\xba\\xf1 2016 \\xf0\\xb3 germany', u'\\xf0\\xbe\\xf0\\xba\\xf1 2016 \\xf0\\xb3 in', u'\\xf0\\xbe\\xf0\\xba\\xf1 2016 \\xf0\\xb3 the', u'\\xf0\\xbe\\xf0\\xba\\xf1 2016 \\xf0\\xb3 these', u'\\xf8\\xb9\\xf8', u'\\xf8\\xb9\\xf8 during', u'\\xf8\\xb9\\xf8 during the', u'\\xf8\\xb9\\xf8 during the year', u'\\xf8\\xb9\\xf8 on', u'\\xf8\\xb9\\xf8 on 22', u'\\xf8\\xb9\\xf8 on 22 october']\n"
     ]
    }
   ],
   "source": [
    "# last 50 features\n",
    "print vect.get_feature_names()[-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK: package that helps combining words that make most sense. After features, we only have words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the fake/real with Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93307024467245459"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test model on the whole data then do a cross valdiation\n",
    "vect = CountVectorizer()\n",
    "Xdtm = vect.fit_transform(X)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(Xdtm, y)\n",
    "nb.score(Xdtm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886363636364\n"
     ]
    }
   ],
   "source": [
    "# make a countvectorizer for a train test split\n",
    "vect = CountVectorizer()\n",
    "# create document-term matrices\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# use multinomial naive bayes with document feature matrix, NOT the text column\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "# calculate accuracy\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "either both or neither of x and y should be given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-3798ad544024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# calculate null accuracy, which is the accuracy of our null model (just guessing the most common thing)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_test_binary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'FAKE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'REAL'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_binary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_test_binary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: either both or neither of x and y should be given"
     ]
    }
   ],
   "source": [
    "# calculate null accuracy, which is the accuracy of our null model (just guessing the most common thing)\n",
    "y_test_binary = np.where(y_test=='FAKE', 'REAL')\n",
    "max(y_test_binary.mean(), 1 - y_test_binary.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on new text\n",
    "new_text = [\"I had a decent time at this restaurant. The food was delicious but the service was poor. I recommend the salad but do not eat the french fries.\"]\n",
    "new_text_transform = vect.transform(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'FAKE'], \n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(new_text_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCISE define a function, tokenize_test,  that does five things:\n",
    "def tokenize_test(vect):\n",
    "    nb = MultinomialNB()\n",
    "    X_dtm = vect.fit_transform(X)\n",
    "    print 'Features: ', X_dtm.shape[1]\n",
    "    print 'Accuracy: ', cross_val_score(nb, X_dtm, y, cv=5, scoring='accuracy').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  1417546\n",
      "Accuracy:  0.901971396531\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "# Here to increase the accuracy, we need to increase the range of the words.\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show vectorizer options\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  3913950\n",
      "Accuracy:  0.91980793926\n"
     ]
    }
   ],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 3))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set of stop words\n",
    "# print vect.get_stop_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Other CountVectorizer Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **max_features:** int or None, default=None\n",
    "- If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  90\n",
      "Accuracy:  0.795576570893\n"
     ]
    }
   ],
   "source": [
    "# remove English stop words and only keep 100 features, MUCH FASTER\n",
    "vect = CountVectorizer(stop_words='english', max_features=90)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'000', u'2016', u'according', u'america', u'american', u'americans', u'bush', u'called', u'campaign', u'candidate', u'change', u'clinton', u'congress', u'country', u'cruz', u'day', u'debate', u'democratic', u'democrats', u'did', u'does', u'donald', u'don\\xe2', u'election', u'far', u'federal', u'going', u'good', u'gop', u'government', u'hillary', u'house', u'including', u'it\\xe2', u'i\\xe2', u'just', u'know', u'law', u'like', u'long', u'make', u'media', u'military', u'national', u'need', u'new', u'news', u'obama', u'party', u'people', u'percent', u'police', u'policy', u'political', u'power', u'president', u'presidential', u'public', u'republican', u'republicans', u'right', u'russia', u'said', u'sanders', u'say', u'says', u'security', u'state', u'states', u'support', u'think', u'time', u'told', u'trump', u'trump\\xe2', u'united', u'use', u've', u'vote', u'voters', u'want', u'war', u'washington', u'way', u'week', u'white', u'work', u'world', u'year', u'years']\n"
     ]
    }
   ],
   "source": [
    "# all 100 features\n",
    "print vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  1000\n",
      "Accuracy:  0.826360070968\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 3-grams, and limit the number of features\n",
    "vect = CountVectorizer(ngram_range=(1, 3), max_features=1000)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams, and only include terms that appear at least 3 times\n",
    "# vect = CountVectorizer(ngram_range=(1, 2), min_df=3)\n",
    "# tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Introduction to TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob: \"Simplified Text Processing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     U.S. Secretary of State John F. Kerry said Mon...\n",
      "3     â Kaydee King (@KaydeeKing) November 9, 2016...\n",
      "4     It's primary day in New York and front-runners...\n",
      "5       \\nIâm not an immigrant, but my grandparent...\n",
      "6     Share This Baylee Luciani (left), Screenshot o...\n",
      "7     A Czech stockbroker who saved more than 650 Je...\n",
      "8     Hillary Clinton and Donald Trump made some ina...\n",
      "9     Iranian negotiators reportedly have made a las...\n",
      "10    CEDAR RAPIDS, Iowa â âI had one of the mos...\n",
      "11    Donald Trumpâs organizational problems have ...\n",
      "12    Click Here To Learn More About Alexandra's Per...\n",
      "13    October 31, 2016 at 4:52 am \\nPretty factual e...\n",
      "14    Killing Obama administration rules, dismantlin...\n",
      "15    As more women move into high offices,Â they of...\n",
      "16    Shocking! Michele Obama & Hillary Caught Glamo...\n",
      "17    0 \\nHillary Clinton has barely just lost the p...\n",
      "18    Washington (CNN) For months, the White House a...\n",
      "19    While paging through Pew's best data visualiza...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print the first review\n",
    "print news_real_fake.text[2:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save it as a TextBlob object\n",
    "review = TextBlob(news_real_fake.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([u'Daniel', u'Greenfield', u'a', u'Shillman', u'Journalism', u'Fellow', u'at', u'the', u'Freedom', u'Center', u'is', u'a', u'New', u'York', u'writer', u'focusing', u'on', u'radical', u'Islam', u'In', u'the', u'final', u'stretch', u'of', u'the', u'election', u'Hillary', u'Rodham', u'Clinton', u'has', u'gone', u'to', u'war', u'with', u'the', u'FBI', u'The', u'word', u'\\xe2\\x80\\x9cunprecedented\\xe2\\x80\\x9d', u'has', u'been', u'thrown', u'around', u'so', u'often', u'this', u'election', u'that', u'it', u'ought'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the words\n",
    "review.words[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Daniel Greenfield, a Shillman Journalism Fellow at the Freedom Center, is a New York writer focusing on radical Islam.\"),\n",
       " Sentence(\"In the final stretch of the election, Hillary Rodham Clinton has gone to war with the FBI.\"),\n",
       " Sentence(\"The word âunprecedentedâ has been thrown around so often this election that it ought to be retired.\"),\n",
       " Sentence(\"But itâs still unprecedented for the nominee of a major political party to go war with the FBI.\"),\n",
       " Sentence(\"But thatâs exactly what Hillary and her people have done.\"),\n",
       " Sentence(\"Coma patients just waking up now and watching an hour of CNN from their hospital beds would assume that FBI Director James Comey is Hillaryâs opponent in this election.\"),\n",
       " Sentence(\"The FBI is under attack by everyone from Obama to CNN.\")]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the sentences\n",
    "review.sentences[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"daniel greenfield, a shillman journalism fellow at the freedom center, is a new york writer focusing on radical islam. \n",
       "in the final stretch of the election, hillary rodham clinton has gone to war with the fbi. \n",
       "the word âunprecedentedâ has been thrown around so often this election that it ought to be retired. but itâs still unprecedented for the nominee of a major political party to go war with the fbi. \n",
       "but thatâs exactly what hillary and her people have done. coma patients just waking up now and watching an hour of cnn from their hospital beds would assume that fbi director james comey is hillaryâs opponent in this election. \n",
       "the fbi is under attack by everyone from obama to cnn. hillaryâs people have circulated a letter attacking comey. there are currently more media hit pieces lambasting him than targeting trump. it wouldnât be too surprising if the clintons or their allies were to start running attack ads against the fbi. \n",
       "the fbiâs leadership is being warned that the entire left-wing establishment will form a lynch mob if they continue going after hillary. and the fbiâs credibility is being attacked by the media and the democrats to preemptively head off the results of the investigation of the clinton foundation and hillary clinton. \n",
       "the covert struggle between fbi agents and obamaâs doj people has gone explosively public. \n",
       "the new york times has compared comey to j. edgar hoover. its bizarre headline, âjames comey role recalls hooverâs fbi, fairly or notâ practically admits up front that itâs spouting nonsense. the boston globe has published a column calling for comeyâs resignation. not to be outdone, time has an editorial claiming that the scandal is really an attack on all women. \n",
       "james carville appeared on msnbc to remind everyone that he was still alive and insane. he accused comey of coordinating with house republicans and the kgb. and you thought the âvast right wing conspiracyâ was a stretch. \n",
       "countless media stories charge comey with violating procedure. do you know whatâs a procedural violation? emailing classified information stored on your bathroom server. \n",
       "senator harry reid has sent comey a letter accusing him of violating the hatch act. the hatch act is a nice idea that has as much relevance in the age of obama as the tenth amendment. but the cable news spectrum quickly filled with media hacks glancing at the wikipedia article on the hatch act under the table while accusing the fbi director of one of the most awkward conspiracies against hillary ever. \n",
       "if james comey is really out to hurt hillary, he picked one hell of a strange way to do it. \n",
       "not too long ago democrats were breathing a sigh of relief when he gave hillary clinton a pass in a prominent public statement. if he really were out to elect trump by keeping the email scandal going, why did he trash the investigation? was he on the payroll of house republicans and the kgb back then and playing it coy or was it a sudden development where vladimir putin and paul ryan talked him into taking a look at anthony weinerâs computer? \n",
       "either comey is the most cunning fbi director that ever lived or heâs just awkwardly trying to navigate a political mess that has trapped him between a doj leadership whose political futures are tied to hillaryâs victory and his own bureau whose apolitical agents just want to be allowed to do their jobs. \n",
       "the only truly mysterious thing is why hillary and her associates decided to go to war with a respected federal agency. most americans like the fbi while hillary clinton enjoys a 60% unfavorable rating. \n",
       "and itâs an interesting question. \n",
       "hillaryâs old strategy was to lie and deny that the fbi even had a criminal investigation underway. instead her associates insisted that it was a security review. the fbi corrected her and she shrugged it off. but the old breezy denial approach has given way to a savage assault on the fbi. \n",
       "pretending that nothing was wrong was a bad strategy, but it was a better one that picking a fight with the fbi while lunatic clinton associates try to claim that the fbi is really the kgb. \n",
       "there are two possible explanations. \n",
       "hillary clinton might be arrogant enough to lash out at the fbi now that she believes that victory is near. the same kind of hubris that led her to plan her victory fireworks display could lead her to declare a war on the fbi for irritating her during the final miles of her campaign. \n",
       "but the other explanation is that her people panicked. \n",
       "going to war with the fbi is not the behavior of a smart and focused presidential campaign. itâs an act of desperation. when a presidential candidate decides that her only option is to try and destroy the credibility of the fbi, thatâs not hubris, itâs fear of what the fbi might be about to reveal about her. \n",
       "during the original fbi investigation, hillary clinton was confident that she could ride it out. and she had good reason for believing that. but that hillary clinton is gone. in her place is a paranoid wreck. within a short space of time the âpositiveâ clinton campaign promising to unite the country has been replaced by a desperate and flailing operation that has focused all its energy on fighting the fbi. \n",
       "thereâs only one reason for such bizarre behavior. \n",
       "the clinton campaign has decided that an fbi investigation of the latest batch of emails poses a threat to its survival. and so itâs gone all in on fighting the fbi. itâs an unprecedented step born of fear. itâs hard to know whether that fear is justified. but the existence of that fear already tells us a whole lot. \n",
       "clinton loyalists rigged the old investigation. they knew the outcome ahead of time as well as they knew the debate questions. now suddenly they are no longer in control. and they are afraid. \n",
       "you can smell the fear. \n",
       "the fbi has wiretaps from the investigation of the clinton foundation. itâs finding new emails all the time. and clintonworld panicked. the spinmeisters of clintonworld have claimed that the email scandal is just so much smoke without fire. all thatâs here is the appearance of impropriety without any of the substance. but this isnât how you react to smoke. itâs how you respond to a fire. \n",
       "the misguided assault on the fbi tells us that hillary clinton and her allies are afraid of a revelation bigger than the fundamental illegality of her email setup. the email setup was a preemptive cover up. the clinton campaign has panicked badly out of the belief, right or wrong, that whatever crime the illegal setup was meant to cover up is at risk of being exposed. \n",
       "the clintons have weathered countless scandals over the years. whatever they are protecting this time around is bigger than the usual corruption, bribery, sexual assaults and abuses of power that have followed them around throughout the years. this is bigger and more damaging than any of the allegations that have already come out. and they donât want fbi investigators anywhere near it. \n",
       "the campaign against comey is pure intimidation. itâs also a warning. any senior fbi people who value their careers are being warned to stay away. the democrats are closing ranks around their nominee against the fbi. itâs an ugly and unprecedented scene. it may also be their last stand. \n",
       "hillary clinton has awkwardly wound her way through numerous scandals in just this election cycle. but sheâs never shown fear or desperation before. now that has changed. whatever she is afraid of, it lies buried in her emails with huma abedin. and it can bring her down like nothing else has.  \")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some string methods are available\n",
    "review.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a281e9a1e797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Parts-of-speech tagging. Identifies nouns, verbs, adverbs, etc...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# Parts-of-speech tagging. Identifies nouns, verbs, adverbs, etc...\n",
    "review.tags.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS Tags guide: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Stemming and Lemmatization : to find the root of nouns and verbs\n",
    "After predicting features of each text, we now build a new model that finds root of nouns, verbs, and perform a new classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming:**\n",
    "\n",
    "- **What:** Reduce a word to its base/stem/root form\n",
    "- **Why:** Often makes sense to treat related words the same way\n",
    "- **Notes:**\n",
    "    - Uses a \"simple\" and fast rule-based approach\n",
    "    - Stemmed words are usually not shown to users (used for analysis/indexing)\n",
    "    - Some search engines treat words with the same stem as synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize stemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare and contrast the words with their stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([u'Daniel', u'Greenfield', u'a', u'Shillman', u'Journalism', u'Fellow', u'at', u'the', u'Freedom', u'Center', u'is', u'a', u'New', u'York', u'writer', u'focusing', u'on', u'radical', u'Islam', u'In', u'the', u'final', u'stretch', u'of', u'the', u'election', u'Hillary', u'Rodham', u'Clinton', u'has', u'gone', u'to', u'war', u'with', u'the', u'FBI', u'The', u'word', u'\\xe2\\x80\\x9cunprecedented\\xe2\\x80\\x9d', u'has', u'been', u'thrown', u'around', u'so', u'often', u'this', u'election', u'that', u'it', u'ought', u'to', u'be', u'retired', u'But', u'it\\xe2\\x80\\x99s', u'still', u'unprecedented', u'for', u'the', u'nominee', u'of', u'a', u'major', u'political', u'party', u'to', u'go', u'war', u'with', u'the', u'FBI', u'But', u'that\\xe2\\x80\\x99s', u'exactly', u'what', u'Hillary', u'and', u'her', u'people', u'have', u'done', u'Coma', u'patients', u'just', u'waking', u'up', u'now', u'and', u'watching', u'an', u'hour', u'of', u'CNN', u'from', u'their', u'hospital', u'beds', u'would', u'assume', u'that'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.words[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'daniel', u'greenfield', u'a', u'shillman', u'journal', u'fellow', u'at', u'the', u'freedom', u'center', u'is', u'a', u'new', u'york', u'writer', u'focus', u'on', u'radic', u'islam', u'in', u'the', u'final', u'stretch', u'of', u'the', u'elect', u'hillari', u'rodham', u'clinton', u'has', u'gone', u'to', u'war', u'with', u'the', u'fbi', u'the', u'word', u'\\xe2\\x80\\x9cunprecedented\\xe2\\x80\\x9d', u'has', u'been', u'thrown', u'around', u'so', u'often', u'this', u'elect', u'that', u'it', u'ought', u'to', u'be', u'retir', u'but', u'it\\xe2\\x80\\x99', u'still', u'unpreced', u'for', u'the', u'nomine', u'of', u'a', u'major', u'polit', u'parti', u'to', u'go', u'war', u'with', u'the', u'fbi', u'but', u'that\\xe2\\x80\\x99', u'exact', u'what', u'hillari', u'and', u'her', u'peopl', u'have', u'done', u'coma', u'patient', u'just', u'wake', u'up', u'now', u'and', u'watch', u'an', u'hour', u'of', u'cnn', u'from', u'their', u'hospit', u'bed', u'would', u'assum', u'that']\n"
     ]
    }
   ],
   "source": [
    "# stem each word\n",
    "print [stemmer.stem(word) for word in review.words[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'table'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try it with words that look very different when pluralized like indices and octopi\n",
    "lem.lemmatize(\"tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare and contrast the originals words with their \"lemons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Daniel', u'Greenfield', u'a', u'Shillman', u'Journalism', u'Fellow', u'at', u'the', u'Freedom', u'Center', u'is', u'a', u'New', u'York', u'writer', u'focusing', u'on', u'radical', u'Islam', u'In', u'the', u'final', u'stretch', u'of', u'the', u'election', u'Hillary', u'Rodham', u'Clinton', u'has', u'gone', u'to', u'war', u'with', u'the', u'FBI', u'The', u'word', u'\\xe2\\x80\\x9cunprecedented\\xe2\\x80\\x9d', u'has', u'been', u'thrown', u'around', u'so', u'often', u'this', u'election', u'that', u'it', u'ought', u'to', u'be', u'retired', u'But', u'it\\xe2\\x80\\x99s', u'still', u'unprecedented', u'for', u'the', u'nominee', u'of', u'a', u'major', u'political', u'party', u'to', u'go', u'war', u'with', u'the', u'FBI', u'But', u'that\\xe2\\x80\\x99s', u'exactly', u'what', u'Hillary', u'and', u'her', u'people', u'have', u'done', u'Coma', u'patients', u'just', u'waking', u'up', u'now', u'and', u'watching', u'an', u'hour', u'of', u'CNN', u'from', u'their', u'hospital', u'beds', u'would', u'assume', u'that']\n"
     ]
    }
   ],
   "source": [
    "print [word for word in review.words[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Daniel', u'Greenfield', u'a', u'Shillman', u'Journalism', u'Fellow', u'at', u'the', u'Freedom', u'Center', u'is', u'a', u'New', u'York', u'writer', u'focusing', u'on', u'radical', u'Islam', u'In', u'the', u'final', u'stretch', u'of', u'the', u'election', u'Hillary', u'Rodham', u'Clinton', u'ha', u'gone', u'to', u'war', u'with', u'the', u'FBI', u'The', u'word', u'\\xe2\\x80\\x9cunprecedented\\xe2\\x80\\x9d', u'ha', u'been', u'thrown', u'around', u'so', u'often', u'this', u'election', u'that', u'it', u'ought', u'to', u'be', u'retired', u'But', u'it\\xe2\\x80\\x99s', u'still', u'unprecedented', u'for', u'the', u'nominee', u'of', u'a', u'major', u'political', u'party', u'to', u'go', u'war', u'with', u'the', u'FBI', u'But', u'that\\xe2\\x80\\x99s', u'exactly', u'what', u'Hillary', u'and', u'her', u'people', u'have', u'done', u'Coma', u'patient', u'just', u'waking', u'up', u'now', u'and', u'watching', u'an', u'hour', u'of', u'CNN', u'from', u'their', u'hospital', u'bed', u'would', u'assume', u'that']\n"
     ]
    }
   ],
   "source": [
    "# assume every word is a noun\n",
    "print [word.lemmatize(pos='n') for word in review.words[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assume every word is a verb\n",
    "# print [word.lemmatize(pos='v') for word in review.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function that accepts text and returns a list of lemmas\n",
    "def word_tokenize_stem(text):\n",
    "    words = TextBlob(text).words\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "def word_tokenize_lemma(text):\n",
    "    words = TextBlob(text).words\n",
    "    return [word.lemmatize() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  91750\n",
      "Accuracy:  0.898026186437\n"
     ]
    }
   ],
   "source": [
    "# use word_tokenize LEMMA as the feature extraction function (WARNING: SLOW!)\n",
    "# this will lemmatize each word\n",
    "vect = CountVectorizer(analyzer=word_tokenize_stem)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  23856\n",
      "Accuracy:  0.912390384251\n"
     ]
    }
   ],
   "source": [
    "# use word_tokenize STEM as the feature extraction function (WARNING: SLOW!)\n",
    "# this will lemmatize each word\n",
    "vect = CountVectorizer(analyzer=word_tokenize_lemma)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Term Frequency-Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What:** Computes \"relative frequency\" that a word appears in a document compared to its frequency across all documents\n",
    "- **Why:** More useful than \"term frequency\" for identifying \"important\" words in each document (high frequency in that document, low frequency in other documents). Court, ball, shooting, passing will show up frequently in a basketball corpus, but essentially add no meaning.\n",
    "- **Notes:** Used for search engine scoring, text summarization, document clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More details:** [TF-IDF is about what matters](http://planspace.org/20150524-tfidf_is_about_what_matters/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a document-term matrix using TF-IDF\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "dtm = vect.fit_transform(fake.text)\n",
    "features = vect.get_feature_names()\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.06345546814296812, subjectivity=0.5553699772449772)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Apply polarity and sentiment over yelp reviews df\n",
    "fake[\"polarity\"] = fake.text.apply(lambda x:TextBlob(x).polarity)\n",
    "fake[\"subjectivity\"] = fake.text.apply(lambda x:TextBlob(x).subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake[\"review_length\"] = fake.text.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2329    jewsnews Â© 2015 | JEWSNEWS | It's not news......\n",
       "3162    jewsnews Â© 2015 | JEWSNEWS | It's not news......\n",
       "5572    jewsnews Â© 2015 | JEWSNEWS | It's not news......\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake[fake.polarity == 1].text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171    Share on Twitter The Wildfire is an opinion pl...\n",
       "201    By Vin Armani You know the state is in trouble...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake[(fake.label == 'FAKE') & (fake.polarity < -0.3)][\"text\"].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: text, dtype: object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake[(fake.label == 1) & (fake.polarity > 0.5)][\"text\"].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD3CAYAAAAHQMOGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVTIgJEmV/j+vepz1aMybqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x721ce0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake.subjectivity.plot(kind=\"hist\", bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRRSAIAhChfL/AVHyeMVWlNT/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x590f6320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot scatter plot of polarity vs subjectivity scores\n",
    "plt.scatter(fake.polarity, fake.subjectivity)\n",
    "plt.xlabel(\"Polarity Scores\")\n",
    "plt.ylabel(\"Subjectivity Scores\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEbCAYAAADAsRPLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAhJUpEBIUkqMiAkSUX/H4RhKVkpJbuPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xacb1bef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot boxplots of the polarity by yelp stars\n",
    "fake.boxplot(column='polarity', by='label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Calculating \"spaminess\" of a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                                                                       message  \n",
       "0                                              Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...  \n",
       "1                                                                                                                                Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's  \n",
       "3                                                                                                            U dun say so early hor... U c already then say...  \n",
       "4                                                                                                Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load in ham or spam text dataset\n",
    "df = pd.read_table(\"../../datasets/spam/sms.tsv\",encoding=\"utf-8\", names= [\"label\", \"message\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at null accuracy\n",
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99353912419239054"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.message\n",
    "y = df.label\n",
    "vect =CountVectorizer()\n",
    "Xdtm = vect.fit_transform(X)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(Xdtm,y)\n",
    "nb.score(Xdtm,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8713"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = vect.get_feature_names()\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'00', u'000', u'000pes', u'008704050406', u'0089', u'0121', u'01223585236', u'01223585334', u'0125698789', u'02', u'0207', u'02072069400', u'02073162414', u'02085076972', u'021', u'03', u'04', u'0430', u'05', u'050703', u'0578', u'06', u'07', u'07008009200', u'07046744435', u'07090201529', u'07090298926', u'07099833605', u'07123456789', u'0721072', u'07732584351', u'07734396839', u'07742676969', u'07753741225', u'0776xxxxxxx', u'07781482378', u'07786200117', u'077xxx', u'078', u'07801543489', u'07808', u'07808247860', u'07808726822', u'07815296484', u'07821230901', u'078498', u'07880867867', u'0789xxxxxxx', u'07946746291', u'0796xxxxxx']\n"
     ]
    }
   ],
   "source": [
    "#Print first 50 features\n",
    "print vect.get_feature_names()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'fifteen', u'fifth', u'fifty', u'fight', u'fighting', u'fightng', u'fights', u'figure', u'figures', u'figuring', u'file', u'files', u'fill', u'filled', u'filling', u'fills', u'film', u'films', u'filth', u'filthy', u'filthyguys', u'final', u'finalise', u'finally', u'finance', u'financial', u'find', u'finding', u'finds', u'fine', u'finest', u'fingers', u'finish', u'finishd', u'finished', u'finishes', u'finishing', u'fink', u'finn', u'fire', u'fired', u'firefox', u'fireplace', u'fires', u'firmware', u'firsg', u'first', u'fish', u'fishhead', u'fishrman']\n"
     ]
    }
   ],
   "source": [
    "#Print random slice of features\n",
    "print vect.get_feature_names()[3200:3250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   1., ...,   1.,   0.,   1.],\n",
       "       [ 10.,  29.,   0., ...,   0.,   1.,   0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many times does a word appear in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8713)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1., ...,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_token_count = nb.feature_count_[0,:]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.,  29.,   0., ...,   0.,   1.,   0.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missions</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residency</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reset</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chat80155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tight</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>another</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentleman</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply</th>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4the</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virgin</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ham  spam\n",
       "token                \n",
       "missions    1.0   0.0\n",
       "residency   1.0   0.0\n",
       "reset       1.0   0.0\n",
       "chat80155   0.0   1.0\n",
       "tight       2.0   0.0\n",
       "another    35.0   2.0\n",
       "gentleman   3.0   0.0\n",
       "apply       2.0  30.0\n",
       "4the        1.0   0.0\n",
       "virgin      1.0   1.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "df_tokens = pd.DataFrame({'token':tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')\n",
    "df_tokens.sample(10, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missions</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residency</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reset</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chat80155</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tight</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>another</th>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentleman</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply</th>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4the</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virgin</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ham  spam\n",
       "token                \n",
       "missions    2.0   1.0\n",
       "residency   2.0   1.0\n",
       "reset       2.0   1.0\n",
       "chat80155   1.0   2.0\n",
       "tight       3.0   1.0\n",
       "another    36.0   3.0\n",
       "gentleman   4.0   1.0\n",
       "apply       3.0  31.0\n",
       "4the        2.0   1.0\n",
       "virgin      2.0   2.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0\n",
    "df_tokens['ham'] = df_tokens.ham + 1\n",
    "df_tokens['spam'] = df_tokens.spam + 1\n",
    "df_tokens.sample(10, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4825.,   747.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missions</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residency</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reset</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chat80155</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.002677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tight</th>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>another</th>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.004016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentleman</th>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply</th>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.041499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4the</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virgin</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.002677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ham      spam\n",
       "token                        \n",
       "missions   0.000415  0.001339\n",
       "residency  0.000415  0.001339\n",
       "reset      0.000415  0.001339\n",
       "chat80155  0.000207  0.002677\n",
       "tight      0.000622  0.001339\n",
       "another    0.007461  0.004016\n",
       "gentleman  0.000829  0.001339\n",
       "apply      0.000622  0.041499\n",
       "4the       0.000415  0.001339\n",
       "virgin     0.000415  0.002677"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ham and spam counts into frequencies\n",
    "df_tokens['ham'] = df_tokens.ham / nb.class_count_[0]\n",
    "df_tokens['spam'] = df_tokens.spam / nb.class_count_[1]\n",
    "df_tokens.sample(10, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missions</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>3.229585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residency</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>3.229585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reset</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>3.229585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chat80155</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>12.918340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tight</th>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>2.153057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>another</th>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.538264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentleman</th>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>1.614793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply</th>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.041499</td>\n",
       "      <td>66.744757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4the</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>3.229585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virgin</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>6.459170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ham      spam  spam_ratio\n",
       "token                                    \n",
       "missions   0.000415  0.001339    3.229585\n",
       "residency  0.000415  0.001339    3.229585\n",
       "reset      0.000415  0.001339    3.229585\n",
       "chat80155  0.000207  0.002677   12.918340\n",
       "tight      0.000622  0.001339    2.153057\n",
       "another    0.007461  0.004016    0.538264\n",
       "gentleman  0.000829  0.001339    1.614793\n",
       "apply      0.000622  0.041499   66.744757\n",
       "4the       0.000415  0.001339    3.229585\n",
       "virgin     0.000415  0.002677    6.459170"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ratio of spam-to-ham for each token\n",
    "df_tokens['spam_ratio'] = df_tokens.spam / df_tokens.ham\n",
    "df_tokens.sample(10, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claim</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.152610</td>\n",
       "      <td>736.345382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prize</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.125837</td>\n",
       "      <td>607.161981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150p</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>465.060241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tone</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.081660</td>\n",
       "      <td>394.009371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.069612</td>\n",
       "      <td>335.876841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guaranteed</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.068273</td>\n",
       "      <td>329.417671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>290.662651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>290.662651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>271.285141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awarded</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.052209</td>\n",
       "      <td>251.907631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ham      spam  spam_ratio\n",
       "token                                     \n",
       "claim       0.000207  0.152610  736.345382\n",
       "prize       0.000207  0.125837  607.161981\n",
       "150p        0.000207  0.096386  465.060241\n",
       "tone        0.000207  0.081660  394.009371\n",
       "18          0.000207  0.069612  335.876841\n",
       "guaranteed  0.000207  0.068273  329.417671\n",
       "500         0.000207  0.060241  290.662651\n",
       "cs          0.000207  0.060241  290.662651\n",
       "1000        0.000207  0.056225  271.285141\n",
       "awarded     0.000207  0.052209  251.907631"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by spam_ratio\n",
    "df_tokens.sort_values('spam_ratio', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.295850066934406"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try looking up scores of different words\n",
    "word = \"win\"\n",
    "df_tokens.loc[word, 'spam_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is NLP after all?\n",
    "---\n",
    "\n",
    "- NLP is a gigantic field\n",
    "- Understanding the basics broadens the types of data you can work with\n",
    "- Simple techniques go a long way\n",
    "- Use scikit-learn for NLP whenever possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab time\n",
    "- There are three other datasets pitchfork album reviews, fake/real news, and political lean.\n",
    "- Pick one of those three datasets and try to build a model that differentiate between good/bad review, real/fake news, or liberal/conservative leaning. Make sure to examine the false positives and the false negatives texts. Use the \"spamminess\" technique on the corpus as well. \n",
    "- Use both count and tfidf vectorizers. Use textblob to determine sentiment and polarity.\n",
    "- I've included some bonus material if you want to explore. \n",
    "    \n",
    "    -How to summarize a text\n",
    "    \n",
    "    -How to use gridsearch to find the optimal parameters for countvectorizer.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Using TF-IDF to Summarize a Yelp Review\n",
    "\n",
    "Reddit's autotldr uses the [SMMRY](http://smmry.com/about) algorithm, which is based on TF-IDF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize():\n",
    "    # choose a random review that is at least 300 characters\n",
    "    review_length = 0\n",
    "    while review_length < 300:\n",
    "        review_id = np.random.randint(0, len(yelp))\n",
    "        review_text = yelp.text[review_id]\n",
    "        review_length = len(review_text)\n",
    "    # create a dictionary of words and their TF-IDF scores\n",
    "    word_scores = {}\n",
    "    for word in TextBlob(review_text).words:\n",
    "        word = word.lower()\n",
    "        if word in features:\n",
    "            word_scores[word] = dtm[review_id, features.index(word)]\n",
    "    \n",
    "    # print words with the top 5 TF-IDF scores\n",
    "    print 'TOP SCORING WORDS:'\n",
    "    top_scores = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for word, score in top_scores:\n",
    "        print word\n",
    "    \n",
    "    # print 5 random words\n",
    "    print '\\n' + 'RANDOM WORDS:'\n",
    "    random_words = np.random.choice(word_scores.keys(), size=5, replace=False)\n",
    "    for word in random_words:\n",
    "        print word\n",
    "    \n",
    "    # print the review\n",
    "    print '\\n' + review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP SCORING WORDS:\n",
      "manager\n",
      "husband\n",
      "reviews\n",
      "mistake\n",
      "fix\n",
      "\n",
      "RANDOM WORDS:\n",
      "bump\n",
      "husband\n",
      "called\n",
      "review\n",
      "calling\n",
      "\n",
      "My husband and I tried this place out since it is fairly close to our house and gets decent reviews.  I drank, my husband ate.  The wine selection is ok and the staff seemed friendly.  My husband's dinner was okay.  I'd probably give this place better reviews had they not attempted to give themselves a $15 bump on their tip.  I'd also probably give them better reviews if the manager would have called me back after leaving a message with a staff member about the charge especially when I left all the details necessary to fix the issue and was promised a call back that afternoon when the manager arrived.  Now, I can only assume it was not an inadvertent mistake since they give me no reason to believe otherwise.  I really would rather not have to keep calling back and chase my $$ down.\r\n",
      "\r\n",
      "Edited review - took them from 1 star to 3 stars since I received a phone call today from a manager and was advised it was a mistake and they credited me back the funds.  Also will be sending me a gift card for the trouble.  Overall, I appreciate the follow up and their efforts to fix the issue and bring me back in.  I was routing for them since the patio seems like a pretty chill place to have some drinks and unwind.\n"
     ]
    }
   ],
   "source": [
    "summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch/pipelining and vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline: function that passes new dataset to minimize the amount of time in running notebooks. \n",
    "Instead of doing one step at a time analysis,we can combine all of those codes in a more efficient way, so it runs all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a pipeline \n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvectorizer',\n",
       "  CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipe steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set range of parameters\n",
    "param_grid = {}\n",
    "param_grid[\"countvectorizer__max_features\"] = [1000,5000,10000]\n",
    "param_grid[\"countvectorizer__ngram_range\"] = [(1,1), (1,2), (2,2)]\n",
    "param_grid[\"countvectorizer__lowercase\"] = [True, False]\n",
    "param_grid[\"countvectorizer__analyzer\"] = [\"word\", word_tokenize_lemma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=Non..., vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'countvectorizer__lowercase': [True, False], 'countvectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)], 'countvectorizer__analyzer': ['word', <function word_tokenize_lemma at 0x1287d40c8>], 'countvectorizer__max_features': [1000, 5000, 10000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will take a while\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'countvectorizer__analyzer': 'word', 'countvectorizer__ngram_range': (1, 2), 'countvectorizer__lowercase': False, 'countvectorizer__max_features': 10000}\n",
      "0.986180904523\n"
     ]
    }
   ],
   "source": [
    "#Look at the best parameters and the best scores\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_jobs',\n",
       " 'verbose',\n",
       " 'estimator__countvectorizer__vocabulary',\n",
       " 'estimator__countvectorizer',\n",
       " 'estimator__countvectorizer__token_pattern',\n",
       " 'estimator__steps',\n",
       " 'param_grid',\n",
       " 'cv',\n",
       " 'estimator__countvectorizer__binary',\n",
       " 'scoring',\n",
       " 'estimator__countvectorizer__analyzer',\n",
       " 'estimator__multinomialnb__alpha',\n",
       " 'estimator__countvectorizer__max_features',\n",
       " 'pre_dispatch',\n",
       " 'estimator__countvectorizer__strip_accents',\n",
       " 'estimator__countvectorizer__stop_words',\n",
       " 'estimator__multinomialnb__fit_prior',\n",
       " 'estimator__countvectorizer__input',\n",
       " 'fit_params',\n",
       " 'estimator__countvectorizer__preprocessor',\n",
       " 'refit',\n",
       " 'iid',\n",
       " 'estimator__countvectorizer__encoding',\n",
       " 'estimator__countvectorizer__decode_error',\n",
       " 'estimator__countvectorizer__tokenizer',\n",
       " 'estimator__countvectorizer__dtype',\n",
       " 'estimator__countvectorizer__ngram_range',\n",
       " 'estimator__countvectorizer__min_df',\n",
       " 'estimator__multinomialnb__class_prior',\n",
       " 'estimator__countvectorizer__lowercase',\n",
       " 'estimator',\n",
       " 'error_score',\n",
       " 'estimator__multinomialnb',\n",
       " 'estimator__countvectorizer__max_df']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Helpful for understanding how to create your param grid.\n",
    "grid.get_params().keys()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://images.efollett.com/htmlroot/images/templates/storeLogos/CA/864.gif\" style=\"float: right;\"> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ECON628-01 \n",
    "### Lecture 1.2 - Principal Component Analysis PCA\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and Horn's Parallel Analysis Lab\n",
    "\n",
    "In this lab you'll practice using PCA on the heptathalon performance data set\n",
    "Horn's Parallel Analysis is a way to determine how many components you should keep after using a PCA on your data. Essentially it will tell you which of your components are likely noise which can be discarded.\n",
    "\n",
    "---\n",
    "\n",
    "### Load packages and heptathalon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hep = pd.read_csv('heptathlon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hep.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep.columns = ['athlete'] + hep.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hep.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hep.iloc[:,1:].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "hep_n = StandardScaler().fit_transform(hep.iloc[:,1:-1])\n",
    "hep_n[:,[0,3,6]] *= -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA().fit(hep_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca1_evec = pca.components_[0]\n",
    "for weight, event in zip(pca1_evec, hep.iloc[:,1:-1].columns):\n",
    "    print event, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca2_evec = pca.components_[2]\n",
    "for weight, event in zip(pca2_evec, hep.iloc[:,1:-1].columns):\n",
    "    print event, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create dataframe excluding athlete and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Examine the correlation between the different events\n",
    "\n",
    "Plot a heatmap if you want to get fancy. What does the correlation matrix tell you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Fit a PCA on the standardized data using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep_pca = PCA()\n",
    "hep_pca.fit(??)\n",
    "stats_pcs = hep_pca.transform(??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create a DataFrame with the principal components\n",
    "\n",
    "Add back in the athelete and score columns from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats_pcs = pd.DataFrame(stats_pcs, columns=['PC'+str(i) for i in range(1,8)])\n",
    "stats_pcs['??'] = hep.iloc[:,0]\n",
    "stats_pcs['??'] = hep.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hep_pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plot the variance explained (ratio) of your components\n",
    "\n",
    "Explain what this chart tells you about your components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hep_pca.explained_............????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(range(1, stats.shape[1]+1), hep_pca.explained_variance_ratio_, lw=2)\n",
    "ax.scatter(range(1, stats.shape[1]+1), hep_pca.explained_variance_ratio_, s=100)\n",
    "ax.set_title('explained variance of components')\n",
    "ax.set_xlabel('principal component')\n",
    "ax.set_ylabel('explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Print out the weights/eigenvectors (.components_ ) with their corresponding variables for PC1 and PC2\n",
    "\n",
    "Based on how the original variables are weighted to calculate the components, how would you describe PC1 and PC2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col, comp in zip(stats.columns, hep_pca.components_[??]):\n",
    "    print col, comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col, comp in zip(stats.columns, hep_pca.components_[??]):\n",
    "    print col, comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats_pcs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plot PC1 vs. PC2. Which athletes are notable on each component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.scatter(stats_pcs.PC1.values, stats_pcs.PC2.values, s=0)\n",
    "\n",
    "for i, txt in enumerate(stats_pcs.athlete.values):\n",
    "    ax.annotate(txt, (0, 0), (stats_pcs.PC1.values[i], stats_pcs.PC2.values[i]),\n",
    "            arrowprops=dict(arrowstyle='<-', color='black', linewidth=1.5),\n",
    "            xycoords='data', textcoords='data', fontsize=12, color=\"black\")\n",
    "\n",
    "ax.set_title('PC1 (run) vs. PC2 (javelin/shot)')\n",
    "ax.set_xlabel('principal component 1 (run)')\n",
    "ax.set_ylabel('principal component 2 (javelin/shot)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plot PC1 vs. score and PC2 vs. score. What does this tell you about the relationship between the events and the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "ax.scatter(stats_pcs.???.????, stats_pcs.???.??, s=100)\n",
    "\n",
    "ax.set_title('PC1 (run) vs. score')\n",
    "ax.set_xlabel('principal component 1 (run)')\n",
    "ax.set_ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "ax.scatter(??, ???, s=100, c='darkred')\n",
    "\n",
    "ax.set_title('PC2 (shot/javelin) vs. score')\n",
    "ax.set_xlabel('principal component 2 (shot/javelin)')\n",
    "ax.set_ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Horn's parallel analysis\n",
    "\n",
    "You can determine the appropriate number of components to keep by using a bootstrapping procedure known as Horn's Parallel Analysis. This is (as far as I know) the gold standard in determining which components aren't noise.\n",
    "\n",
    "How to do the parallel analysis (pseudocode):\n",
    "\n",
    "    for n iterations:\n",
    "        create normally distributed random data the same shape as your data\n",
    "        fit a PCA on the random data\n",
    "        pull out the eigenvalues\n",
    "    select a percentile of the eigenvalues as your threshold (0.5 = median, 0.95 = 95% confidence, etc.)\n",
    "    plot the random component eigenvalues at that percentile against your data's pca eigenvalues\n",
    "    components above the selected percentile are not noise, those under are\n",
    "    \n",
    "    \n",
    "Write a function to perform the parallel analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def horn_parallel_analysis(shape, iters=1000, percentile=95):\n",
    "    pca = PCA(n_components=shape[1])\n",
    "    eigenvals = []\n",
    "    for i in range(iters):\n",
    "        rdata = np.random.normal(0,1,size=shape)\n",
    "        pca.fit(rdata)\n",
    "        eigenvals.append(pca.explained_variance_)\n",
    "    eigenvals = np.array(eigenvals)\n",
    "    return np.percentile(eigenvals, percentile, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Run parallel analysis for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hep_pa = horn_parallel_analysis(hep.iloc[:,1:-1].shape, percentile=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plot the wine eigenvalues (`.variance_explained_`) against the parallel analysis random eigenvalue cutoffs\n",
    "\n",
    "How many components are not noise, based on the chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(range(1, hep.iloc[:,1:-1].shape[1]+1), hep_pca.explained_variance_, lw=2)\n",
    "ax.scatter(range(1, hep.iloc[:,1:-1].shape[1]+1), hep_pca.explained_variance_, s=50)\n",
    "\n",
    "ax.plot(range(1, len(hep_pa)+1), hep_pa, lw=2, color='darkred')\n",
    "ax.scatter(range(1, len(hep_pa)+1), hep_pa, s=40, color='darkred')\n",
    "\n",
    "\n",
    "ax.set_title('Horns parallel analysis on hep data components')\n",
    "ax.set_xlabel('principal component')\n",
    "ax.set_ylabel('eigenvalue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
